# 🤖 Chatbot Local com Ollama e Streamlit

Este projeto é um **chatbot local** construído com `Streamlit` e a biblioteca `ollama`, que permite interagir com modelos de linguagem de forma rápida e leve, diretamente do seu próprio computador.

---

## 📦 Tecnologias Utilizadas

- **Python** – Linguagem de programação  
- **Streamlit** – Framework para criação de aplicações web interativas  
- **Ollama** – Biblioteca para execução de modelos LLM localmente  

---

## 💻 Funcionalidades

- Interface de chat intuitiva via Streamlit  
- Escolha de modelo (exemplo: `llama3:8b`)  
- Histórico de mensagens persistente durante a sessão  
- Botão para limpar o chat a qualquer momento  
- Processamento da conversa com **streaming de respostas** 

---

## 🚀 Como Executar

### 1. Clonar o Repositório

```bash
git clone https://github.com/HeitorDalla/local_chatbot.git
```

### 2. Instalar Dependências

```bash
pip install ollama streamlit
```

### 3. Executar o Script

```bash
python index.py
```

## 🧠 Possíveis Melhorias Futuras

- Suporte a múltiplos modelos de linguagem, permitindo troca dinâmica entre diferentes LLMs.
- Implementar persistência do histórico do chat em banco de dados para conversas longas e reusáveis.
- Adicionar suporte a múltiplos usuários simultâneos com sessões isoladas.
- Criar integração com entrada por voz (microfone) e saída por síntese de voz para uma experiência mais natural.
- Desenvolver uma interface mais rica com abas, personalização do tema e emojis.
- Implementar funcionalidades de moderação e filtro para evitar respostas inadequadas.

---

## 👨‍💻 Autor

- **Heitor Giussani Dalla Villa**  
- 📧 [heitorvillavilla@gmail.com](mailto:heitorvillavilla@gmail.com)  
- 🔗 [LinkedIn](https://www.linkedin.com/in/heitordallavilla)

---

## 📝 Observações Finais

Nenhuma observação final.
